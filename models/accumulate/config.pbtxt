# The MIT License (MIT)
# 
# Copyright (c) 2021, NVIDIA CORPORATION. All rights reserved.
# 
# Permission is hereby granted, free of charge, to any person obtaining a copy of
# this software and associated documentation files (the "Software"), to deal in
# the Software without restriction, including without limitation the rights to
# use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of
# the Software, and to permit persons to whom the Software is furnished to do so,
# subject to the following conditions:
# 
# The above copyright notice and this permission notice shall be included in all
# copies or substantial portions of the Software.
# 
# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS
# FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR
# COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER
# IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
# CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.

name: "accumulate"
backend: "stateful"
max_batch_size: 16
sequence_batching {
  max_sequence_idle_microseconds: 100000000
  oldest {
    max_candidate_sequences: 1280
    #preferred_batch_size: [ 64 ]
    max_queue_delay_microseconds: 2000
  }
 
  control_input [
    {
      name: "ResetSequence"
      control [
        {
          kind: CONTROL_SEQUENCE_START
          int32_false_true: [ 0, 1 ]
        }
      ]
    },
    {
      name: "EndSequence"
      control [
        {
          kind: CONTROL_SEQUENCE_END
          int32_false_true: [ 0, 1 ]
        }
      ]
    },
    {
      name: "CORRID"
      control [
        {
          kind: CONTROL_SEQUENCE_CORRID
          # data_type: TYPE_STRING
          data_type: TYPE_UINT64
        }
      ]
    }
  ]
}


#Enable below lines for the model with TopK 
input [
  {
    name: "Input"
    data_type: TYPE_FP32
    dims: [ 4, -1, 5 ]
  }
]
output [
  {
    name: "Output"
    data_type: TYPE_FP32
    dims: [ 4, -1, 5]
  }
]

parameters [
  {
    key: "onnx_file_name"
    value: { string_value: "accumulate.onnx" }
  },
  {
    key: "state_pairs"
    value: { string_value: "<<<Accumulate_In, Accumulate_Out>>>" }
  },
  {
    key: "initial_buffer_size"
    value: { string_value: "512" }
  },
  {
    key: "subsequent_buffer_size"
    value: { string_value: "100" }
  },
  {
    key: "buffer_alloc_threshold"
    value: { string_value: "32" }
  },
  {
    key: "buffer_dealloc_threshold"
    value: { string_value: "200" }
  },
  {
    key: "error_inject_rate"
    value: { string_value: "15" }
  },
  {
    key: "ort_ep"
    # ORT EP to run the model for GPU execution. Ignored if KIND_CPU is set for 
    # instance_group
    value: { string_value: "trt" }
    # value: { string_value: "cuda" }
  },
  {
    key: "compute_precision"
    # Set to fp16 for Tensor Core compute for TRT EP
    # value: { string_value: "fp16" }
    value: { string_value: "fp32" }
  },
  {
    key: "store_states_as_fp16"
    # Store the states as FP16 to reduce memory usage (may impact accuracy)
    # Default: 0, disabled
    value: { string_value: "0" }
  },
  {
    key: "metric_logging_frequency_seconds"
    # Average/Max batch size logging frequency in seconds::
    # Default: 0, disabled
    value: { string_value: "2" }
  },
  {
    key: "always_pad_to_max_batch"
    # Always pad current batch to max batch size
    #  Default: 0, disabled
    value: { string_value: "0" }
  },
  {
    key: "enable_trt_caching"
    # Enable TRT engine caching
    #  Default: 0, disabled
    value: { string_value: "1" }
  },
  {
    key: "trt_cache_dir"
    # TRT cache directory, ignored if TRT caching is disabled
    #  Default: /tmp
    value: { string_value: "/tmp/trt_cache" }
  },
  {
    key: "logging_level"
    # Metrics report logging::
    #  NONE: No logs from model runner.
    #  INFO: Only Sequence Reset
    #  VERBOSE: INFO + all metrics
    value: { string_value: "VERBOSE" }
  }
]

# Set the instance group to KIND_CPU for running on CPU only with ORT-CPU EP
instance_group [
  {
    count: 2
    kind: KIND_GPU
    gpus: [0]
    #count: 1
    #kind: KIND_CPU
  }
]
